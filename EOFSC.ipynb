{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import math\n",
    "from statistics import mode\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_with contains 26 input features and class label but not with patient id (1040, 27)\n",
      "X contains 26 input features only and there is no output label (1040, 26)\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[[1.809000e+00 1.485100e-04 6.800000e-01 8.430000e-01 2.040000e+00\n",
      "  7.881000e+00 7.820000e-01 2.690000e+00 4.543000e+00 1.107300e+01\n",
      "  8.069000e+00 9.255540e-01 9.748100e-02 1.347200e+01 1.192600e+02\n",
      "  1.216300e+02 8.028000e+00 1.081440e+02 1.375460e+02 6.200000e+01\n",
      "  6.000000e+01 8.211245e-03 5.658130e-04 1.818200e+01 1.000000e+00\n",
      "  3.387000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Importing the Train Data \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:\\PD Dataset From Laptop/train_data.txt\")\n",
    "X_first = numpy.array(df)\n",
    "X_train = numpy.delete(X_first, 27, 1)\n",
    "X_withlabels = numpy.delete(X_train, 0,1)\n",
    "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
    "X = numpy.delete(X_withlabels, 26, 1)\n",
    "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
    "Y = X_withlabels[: ,26]\n",
    "print(Y)\n",
    "print(X[[1039]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Dataset No======================================================================= 0\n",
      "(40,)\n",
      "(40, 27)\n",
      "[   0   26   52   78  104  130  156  182  208  234  260  286  312  338\n",
      "  364  390  416  442  468  494  520  546  572  598  624  650  676  702\n",
      "  728  754  780  806  832  858  884  910  936  962  988 1014]\n",
      "(40, 26)\n",
      "(40,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "#while j<=2:\n",
    "print(\"This is Dataset No=======================================================================\", j)\n",
    "i=1\n",
    "indices = j\n",
    "increment = 26+j\n",
    "while i<=39:\n",
    "\n",
    "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
    "    i = i+1\n",
    "    increment = increment+26\n",
    "print(indices.shape)         #Thus we get 40x3=120 indices of 120samples. Now extract those samples from X and Y to get a new Training Set\n",
    "#print(indices)\n",
    "X_train_withlabels = X_withlabels[[indices]]\n",
    "print(X_train_withlabels.shape)\n",
    "Y_New = X_train_withlabels[:, 26]\n",
    "X_1 = numpy.delete(X_train_withlabels, 26, 1)\n",
    "print(indices)\n",
    "print(X_1.shape)\n",
    "print(Y_New.shape)\n",
    "print(Y_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Dataset No======================================================================= 1\n",
      "(40,)\n",
      "(40, 27)\n",
      "[   1   27   53   79  105  131  157  183  209  235  261  287  313  339\n",
      "  365  391  417  443  469  495  521  547  573  599  625  651  677  703\n",
      "  729  755  781  807  833  859  885  911  937  963  989 1015]\n",
      "(40, 26)\n",
      "(40,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "#while j<=2:\n",
    "print(\"This is Dataset No=======================================================================\", j)\n",
    "i=1\n",
    "indices = j\n",
    "increment = 26+j\n",
    "while i<=39:\n",
    "\n",
    "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
    "    i = i+1\n",
    "    increment = increment+26\n",
    "print(indices.shape)         #Thus we get 40x3=120 indices of 120samples. Now extract those samples from X and Y to get a new Training Set\n",
    "#print(indices)\n",
    "X_train_withlabels = X_withlabels[[indices]]\n",
    "print(X_train_withlabels.shape)\n",
    "Y_New = X_train_withlabels[:, 26]\n",
    "X_2 = numpy.delete(X_train_withlabels, 26, 1)\n",
    "print(indices)\n",
    "print(X_2.shape)\n",
    "print(Y_New.shape)\n",
    "print(Y_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Dataset No======================================================================= 2\n",
      "(40,)\n",
      "(40, 27)\n",
      "[   2   28   54   80  106  132  158  184  210  236  262  288  314  340\n",
      "  366  392  418  444  470  496  522  548  574  600  626  652  678  704\n",
      "  730  756  782  808  834  860  886  912  938  964  990 1016]\n",
      "(40, 26)\n",
      "(40,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "j = 2\n",
    "#while j<=2:\n",
    "print(\"This is Dataset No=======================================================================\", j)\n",
    "i=1\n",
    "indices = j\n",
    "increment = 26+j\n",
    "while i<=39:\n",
    "\n",
    "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
    "    i = i+1\n",
    "    increment = increment+26\n",
    "print(indices.shape)         #Thus we get 40x3=120 indices of 120samples. Now extract those samples from X and Y to get a new Training Set\n",
    "#print(indices)\n",
    "X_train_withlabels = X_withlabels[[indices]]\n",
    "print(X_train_withlabels.shape)\n",
    "Y_New = X_train_withlabels[:, 26]\n",
    "X_3 = numpy.delete(X_train_withlabels, 26, 1)\n",
    "print(indices)\n",
    "print(X_3.shape)\n",
    "print(Y_New.shape)\n",
    "print(Y_New)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Model of Dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of selected features =================================== (40, 21)\n",
      "Best Acc ==================================== 87.5\n"
     ]
    }
   ],
   "source": [
    "k=21\n",
    "X_FS = SelectKBest(f_classif, k=k).fit_transform(X_1, Y_New)\n",
    "Best_Acc =0\n",
    "print(\"Size of selected features ===================================\", X_FS.shape)\n",
    "########### LOSO ##############################\n",
    "\n",
    "i = 0\n",
    "cor_class=0\n",
    "LOSO_Acc=0\n",
    "while i<=39:\n",
    "    X_test = X_FS[[i]]\n",
    "    X_train = numpy.delete(X_FS, i, 0)\n",
    "    Y_test = Y_New[[i]]\n",
    "    Y_train = numpy.delete(Y_New, i, 0)\n",
    "    ###############For Each Selected Features, evaluate model performance by trying different nodes############\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1, 18, ), random_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    if(i<=19):\n",
    "        if predictions[0]==1:\n",
    "            cor_class = cor_class+1\n",
    "    if(i>19):\n",
    "        if predictions[0]==0:\n",
    "            cor_class = cor_class+1\n",
    "\n",
    "    i = i+1\n",
    "LOSO_Acc= (cor_class/40)*100\n",
    "if (LOSO_Acc>=Best_Acc):\n",
    "    Best_Acc = LOSO_Acc\n",
    "    print(\"Best Acc ====================================\", Best_Acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Model of Dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of selected features =================================== (40, 7)\n",
      "Best Acc ==================================== 90.0\n"
     ]
    }
   ],
   "source": [
    "k=7\n",
    "X_FS = SelectKBest(f_classif, k=k).fit_transform(X_2, Y_New)\n",
    "Best_Acc =0\n",
    "print(\"Size of selected features ===================================\", X_FS.shape)\n",
    "########### LOSO ##############################\n",
    "\n",
    "i = 0\n",
    "cor_class=0\n",
    "LOSO_Acc=0\n",
    "while i<=39:\n",
    "    X_test = X_FS[[i]]\n",
    "    X_train = numpy.delete(X_FS, i, 0)\n",
    "    Y_test = Y_New[[i]]\n",
    "    Y_train = numpy.delete(Y_New, i, 0)\n",
    "    ###############For Each Selected Features, evaluate model performance by trying different nodes############\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 4, ), random_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    if(i<=19):\n",
    "        if predictions[0]==1:\n",
    "            cor_class = cor_class+1\n",
    "    if(i>19):\n",
    "        if predictions[0]==0:\n",
    "            cor_class = cor_class+1\n",
    "\n",
    "    i = i+1\n",
    "LOSO_Acc= (cor_class/40)*100\n",
    "if (LOSO_Acc>=Best_Acc):\n",
    "    Best_Acc = LOSO_Acc\n",
    "    print(\"Best Acc ====================================\", Best_Acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Model Dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of selected features =================================== (40, 25)\n",
      "Best Acc ==================================== 87.5\n"
     ]
    }
   ],
   "source": [
    "k=25\n",
    "X_FS = SelectKBest(f_classif, k=k).fit_transform(X_3, Y_New)\n",
    "Best_Acc =0\n",
    "print(\"Size of selected features ===================================\", X_FS.shape)\n",
    "########### LOSO ##############################\n",
    "\n",
    "i = 0\n",
    "cor_class=0\n",
    "LOSO_Acc=0\n",
    "while i<=39:\n",
    "    X_test = X_FS[[i]]\n",
    "    X_train = numpy.delete(X_FS, i, 0)\n",
    "    Y_test = Y_New[[i]]\n",
    "    Y_train = numpy.delete(Y_New, i, 0)\n",
    "    ###############For Each Selected Features, evaluate model performance by trying different nodes############\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 6, ), random_state=1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    if(i<=19):\n",
    "        if predictions[0]==1:\n",
    "            cor_class = cor_class+1\n",
    "    if(i>19):\n",
    "        if predictions[0]==0:\n",
    "            cor_class = cor_class+1\n",
    "\n",
    "    i = i+1\n",
    "LOSO_Acc= (cor_class/40)*100\n",
    "if (LOSO_Acc>=Best_Acc):\n",
    "    Best_Acc = LOSO_Acc\n",
    "    print(\"Best Acc ====================================\", Best_Acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Development (EOFSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Acc ==================================== 95.0\n",
      "Sen ================================== 100.0\n",
      "Spec ================================= 90.0\n",
      "Mathew Correlation Coefficients MCC= 0.9045340337332909\n"
     ]
    }
   ],
   "source": [
    "##############FS for Dataset 1#################\n",
    "k=21\n",
    "X_FS_1 = SelectKBest(f_classif, k=k).fit_transform(X_1, Y_New)\n",
    "###############################################################\n",
    "\n",
    "##############FS for Dataset 2#################\n",
    "k=7\n",
    "X_FS_2 = SelectKBest(f_classif, k=k).fit_transform(X_2, Y_New)\n",
    "###############################################################\n",
    "\n",
    "##############FS for Dataset 3#################\n",
    "k=25\n",
    "X_FS_3 = SelectKBest(f_classif, k=k).fit_transform(X_3, Y_New)\n",
    "###############################################################\n",
    "\n",
    "\n",
    "########### LOSO ##############################\n",
    "Best_Acc =0\n",
    "TP =0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "i = 0\n",
    "cor_class=0\n",
    "LOSO_Acc=0\n",
    "while i<=39:\n",
    "    ###########Generating Three Different Training and Testing Datasets#############\n",
    "    X_test_1 = X_FS_1[[i]]\n",
    "    X_train_1 = numpy.delete(X_FS_1, i, 0)\n",
    "    #################################################\n",
    "    \n",
    "    X_test_2 = X_FS_2[[i]]\n",
    "    X_train_2 = numpy.delete(X_FS_2, i, 0)\n",
    "    #################################################\n",
    "    \n",
    "    X_test_3 = X_FS_3[[i]]\n",
    "    X_train_3 = numpy.delete(X_FS_3, i, 0)\n",
    "    #################################################\n",
    "    \n",
    "    Y_test = Y_New[[i]]\n",
    "    Y_train = numpy.delete(Y_New, i, 0)\n",
    "    \n",
    "    ###################Creating and Fitting three different optimal models#########################\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1, 18, ), random_state=1)\n",
    "    model.fit(X_train_1, Y_train)\n",
    "    Y_Pred_1 = model.predict(X_test_1)\n",
    "\n",
    "    ###################Creating and Fitting three different optimal models#########################\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 4, ), random_state=1)\n",
    "    model.fit(X_train_2, Y_train)\n",
    "    Y_Pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    ###################Creating and Fitting three different optimal models#########################\n",
    "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 6, ), random_state=1)\n",
    "    model.fit(X_train_3, Y_train)\n",
    "    Y_Pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    ##############Ensembling the Three Outputs#########################\n",
    "    \n",
    "    Y_Net = Y_Pred_1 + Y_Pred_2 + Y_Pred_3\n",
    "    if (Y_Net<2):\n",
    "        final_pred=0\n",
    "    if(Y_Net>=2):\n",
    "        final_pred=1\n",
    "    \n",
    "    \n",
    "    if(i<=19):\n",
    "        if final_pred == 1:\n",
    "            cor_class = cor_class+1\n",
    "            TP = TP+1\n",
    "    if(i>19):\n",
    "        if final_pred == 0:\n",
    "            cor_class = cor_class+1\n",
    "            TN = TN+1\n",
    "\n",
    "    i = i+1\n",
    "LOSO_Acc= (cor_class/40)*100\n",
    "FP = 20-TN\n",
    "FN = 20-TP\n",
    "Sen = TP/20\n",
    "Spec = TN/20\n",
    "if (LOSO_Acc>=Best_Acc):\n",
    "    Best_Acc = LOSO_Acc\n",
    "    print(\"Best Acc ====================================\", Best_Acc)\n",
    "    print(\"Sen ==================================\", Sen*100)\n",
    "    print(\"Spec =================================\", Spec*100)\n",
    "    print(\"Mathew Correlation Coefficients MCC=\", (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
